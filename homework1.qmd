---
title: "Homerwork 1"
author: "PATRICK COOK"
date: 2023-05-14
format: 
  docx: default
  html:
    toc: true
    toc_float: true
    code-fold: true
editor: visual
---

```{r}
#| label: load-libraries
#| echo: false # This option disables the printing of code (only output is displayed).
#| message: false
#| warning: false

library(tidyverse)
library(nycflights13)
library(skimr)

```

# Data Manipulation

## Problem 1: Use logical operators to find flights that:

```         
-   Had an arrival delay of two or more hours (\> 120 minutes)
-   Flew to Houston (IAH or HOU)
-   Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
-   Departed in summer (July, August, and September)
-   Arrived more than two hours late, but didn't leave late
-   Were delayed by at least an hour, but made up over 30 minutes in flight
```

```{r}
#| label: problem-1g
  glimpse(flights)


# Had an arrival delay of two or more hours (> 120 minutes)
problem1A <- flights %>%
  
  filter(arr_delay >= 120, 

# Flew to Houston (IAH or HOU)
  dest %in% c("IAH", "HOU"), 

# Were operated by United (`UA`), American (`AA`), or Delta (`DL`)
  carrier %in% c("UA", "AA", "DL"), 

# Departed in summer (July, August, and September)
  month %in% c(7, 8, 9),

# Arrived more than two hours late, but didn't leave late (there are no flights that did this, every flight that arrived late by at least 2 hours was already delayed on departure)
    
  dep_delay <= 0)



# Were delayed by at least an hour, but made up over 30 minutes in flight (I have put a # in front of)
problem1B <- flights %>%
  filter(
    dest %in% c("IAH", "HOU"), 
    carrier %in% c("UA", "AA", "DL"), 
    month %in% c(7, 8, 9),
    dep_delay >= 60,
    arr_delay <= 30
    )
  

problem1A
problem1B
```

## Problem 2: What months had the highest and lowest proportion of cancelled flights? Interpret any seasonal patterns. To determine if a flight was cancelled use the following code

<!-- -->

```         
```

```{r}
#| label: problem-2

flights %>% 
  filter(is.na(dep_time)) 

# What months had the highest and lowest % of cancelled flights?

problem2 <- flights %>%
  group_by(month) %>%
  summarise(total_flights = n(),
  number_cancelled = sum((is.na(dep_time))),
  proportion_cancelled = number_cancelled/total_flights*100)
  #Calculating the total flights, total cancelled flights, and proportion of         flights cancelled for each of   the 12 months in 2013
problem2


highest_cancelled_month <- problem2 %>% 
  filter(proportion_cancelled == max(proportion_cancelled)) %>% 
  pull(month, proportion_cancelled)
  #Pulling the month with the highest proportion of cancelled flights, which is   `month 2 (February)
highest_cancelled_month


lowest_cancelled_month <- problem2 %>% 
  filter(proportion_cancelled == min(proportion_cancelled)) %>% 
  pull(month, proportion_cancelled)
  #Pulling the month with the lowest proportion of cancelled flights, which is       month 10 (November)
lowest_cancelled_month

```

## Problem 3: What plane (specified by the `tailnum` variable) traveled the most times from New York City airports in 2013? Please `left_join()` the resulting table with the table `planes` (also included in the `nycflights13` package).

For the plane with the greatest number of flights and that had more than 50 seats, please create a table where it flew to during 2013.

```{r}


#Left joining tables
joined <- left_join(planes, flights, by = 'tailnum') %>% 
  group_by(tailnum)

joined


#Finding the plane with largest number of flights from NYC and with more than 50 seats
number_of_flights <- joined %>% 
  filter(origin %in% c("EWR", "LGA", "JFK"),
         seats >= 50
         ) %>% 
  count(tailnum) %>% 
  arrange(desc(n))%>%
  head(1) 
  #We can see that it is plane N328AA with 393 flights
number_of_flights


#Isolating tail number
number_of_flights$tailnum


#Finding unique destinations for this plane
table <- joined %>% 
  filter(tailnum == number_of_flights$tailnum) %>% 
  group_by(dest) %>% 
  select(dest)

unique(table)


```

## Problem 4: The `nycflights13` package includes a table (`weather`) that describes the weather during 2013. Use that table to answer the following questions:

```         
-   What is the distribution of temperature (`temp`) in July 2013? Identify any important outliers in terms of the `wind_speed` variable.
-   What is the relationship between `dewp` and `humid`?
-   What is the relationship between `precip` and `visib`?
```

```{r}


#A: Finding distribution of temperature in July 2013
july_weather <- weather %>% 
  filter(month == 7) %>% 
  select(temp) %>%
  drop_na()

ggplot(july_weather, aes(x=temp)) +
    geom_histogram(binwidth=.5, colour="black", fill="white")

summary(july_weather)

  #To find the distribution of temperature I have drawn a histogram of the temperature in July, which       roughly shows a normal distribution. I also have shown the summary statistics, which shows that the       minimum temperature was 64.04, the maximum was 100.04, and the mean was 80.07


#B: Finding outliers in wind_speed (in July)

wind_speed_outliers <- weather %>% 
  filter(month == 7) %>% 
  select(wind_speed)

boxplot(wind_speed_outliers)

  #To find outliers I have drawn a boxplot of the wind speed in July, this shows that there are 3 outliers   where the wind speed was significantly high


#C: Finding relationship between 'dewp' and 'humid'

weather %>%
  filter(month == 7) %>% 
  select(dewp,humid) %>% 
  GGally::ggpairs()

  #We can see that in July, there is a positive correlation between dewp and humid of 0.535 which is     `   statistically  significant


#D: Finding relationship between 'precip' and 'visib'

weather %>% 
  filter(month == 7) %>% 
  select(precip, visib) %>% 
  GGally::ggpairs()

  #We see that in July, there is a negative relationship between dewp and humid of -0.241, suggesting that   typically when there is precipitation, the level of visibility will be low, this makes sense!



```

## Problem 5: Use the `flights` and `planes` tables to answer the following questions:

```         
-   How many planes have a missing date of manufacture?
-   What are the five most common manufacturers?
-   Has the distribution of manufacturer changed over time as reflected by the airplanes flying from NYC in 2013? (Hint: you may need to use case_when() to recode the manufacturer name and collapse rare vendors into a category called Other.)
```

```{r}
#A: Number of planes with missing date of manufacture

planes %>% 
  filter(is.na(year)) %>% 
  nrow()

#B: Five most common manufacturers
most_common_planes <- planes %>% 
  group_by(manufacturer) %>% 
  count(manufacturer) %>% 
  arrange(desc(n)) %>% 
  head(5)

most_common_planes


#B: Has the distribution of manufacturer changed over time
common_manufacturer <- planes %>%
  group_by(manufacturer) %>%
  count(manufacturer) %>%
  mutate(manufacturer = case_when(
    n >= 2 ~ as.character(manufacturer),
    TRUE ~ "Other"
  )) %>% 
  group_by(manufacturer)

total <- sum(common_manufacturer$n)

common_manufacturer %>%
  group_by(manufacturer) %>% 
  summarize(prop = n/total) %>% 
  arrange(desc(prop))
  #The above code shows me trying to calculate the proportion of each manufacturer for all planes flown in   2013, I struggled to regroup the 'Other' variables together, but I can see that for flights in 2013,      Boeing was by far the most common manufacturer with nearly 50% of planes, followed by Airbus


common_manufacturer_over_time <- planes %>%
  group_by(year) %>% 
  count(manufacturer, sort=TRUE) %>% 
  mutate(prop = n/sum(n)) %>% 
  mutate(manufacturer = case_when(
    n >= 2 ~ as.character(manufacturer),
    TRUE ~ "Other"
  )) %>% 
  group_by(manufacturer, year) %>% 
  summarize(prop = sum(prop)) %>% 
  arrange(year) %>% 
  filter(year >= 1979)
  #This data set now shows the proportion of the planes from each year that were made by each               manufacturer
common_manufacturer_over_time

ggplot(common_manufacturer_over_time, aes(x = year, y = prop, color = manufacturer)) +
  geom_line() +
  labs(x = "Year", y = "% of Manufacturer") +
  scale_color_discrete(name = "Manufacturer") +
  theme(legend.text = element_text(size = 5),
        legend.title = element_text(size = 7),
        legend.key.size = unit(0.5, "cm"))
  #The graph shows how the proportion of planes made by each manufacturer has changed over time. In some cases it has changed significantly from year to year, this could reflect that the plane manufacturers produce a number of planes in a year, then take a break whilst designing the next model of plane

```

## Problem 6: Use the `flights` and `planes` tables to answer the following questions:

```         
-   What is the oldest plane (specified by the tailnum variable) that flew from New York City airports in 2013?
-   How many airplanes that flew from New York City are included in the planes table?
```

```{r}

#A: Finding oldest plane that flew from NYC airports in 2013

oldest_plane <- left_join(planes, flights, by = 'tailnum') %>% 
  arrange(year.x) %>% 
  filter(origin %in% c("EWR", "LGA", "JFK")) %>% 
  #isolating tailnum
  select(tailnum) %>% 
  head(1)
  #We can see that the oldest plane is plane N381AA
oldest_plane


#B: How many airplanes that flew from NYC are in the table

number_of_planes_that_flew_from_nyc <- flights %>% 
  filter(origin %in% c("EWR", "LGA", "JFK")) %>% 
  select(tailnum) %>%
  n_distinct('tailnum', na.rm = TRUE)

number_of_planes_that_flew_from_nyc

  #We can see that 4043 unique planes flew from NYC in 2013


```

## Problem 7: Use the `nycflights13` to answer the following questions:

```         
-   What is the median arrival delay on a month-by-month basis in each airport?
-   For each airline, plot the median arrival delay for each month and origin airport.
```

```{r}

#A: This graph shows the median arrival delay on a month-by-month basis for each airport. I grouped the data by month and origin, and then used the summary function to find the median arrival delay
median_arrival_delay <- flights %>% 
  group_by(month, origin) %>% 
  summarize(median_arr_delay = median(arr_delay, na.rm = TRUE))

ggplot(median_arrival_delay, aes(x = month, fill = origin)) + 
  geom_bar(stat = "count", position = "dodge")




#B: To plot the median per month for each airline, I grouped by carrier, month, and origin. I then used the summary function to calculate the median arrival delay. 

carriers_month <- flights %>% 
  group_by(carrier, month, origin) %>%
  summarise(median_arr_delay = median(arr_delay, na.rm = TRUE)) 

#Then to plot this data, I used a line graph 

ggplot(carriers_month, aes(x = month, y = median_arr_delay, color = carrier)) +
  geom_line() +
  labs(x = "Month", y = "Median Arrival Delay")

```

## Problem 8: Let's take a closer look at what carriers service the route to San Francisco International (SFO). Join the `flights` and `airlines` tables and count which airlines flew the most to SFO. Produce a new dataframe, `fly_into_sfo` that contains three variables: the `name` of the airline, e.g., `United Air Lines Inc.` not `UA`, the count (number) of times it flew to SFO, and the `percent` of the trips that that particular airline flew to SFO.

```{r}

#finding the number of flights into SFO by each airline
fly_into_sfo <- left_join(planes, flights, by = 'tailnum') %>% 
  filter(dest == 'SFO') %>% 
  group_by(carrier) %>% 
  count(carrier)

fly_into_sfo 

#finding the total number of flights into SFO
sum <- sum(fly_into_sfo$n)

sum


#renaming the values for carrier and calculating percentage of flights, also rounding the percentage to 2 decimal places
fly_into_sfo <- fly_into_sfo %>%
  summarize(name = recode(carrier, "AA" = "American Airlines", "B6" = "JetBlue", "DL" = "Delta Air Lines", "UA" = "United Air Lines Inc.", "VX" = "Virgin America"), count = n, percent = (count/sum)*100) %>% 
  mutate(across(where(is.numeric), ~ round(., 2)))

fly_into_sfo

#The resulting table now shows the proportion of flights into SFO by each airline

```

And here is some bonus ggplot code to plot your dataframe

```{r}
#| label: ggplot-flights-toSFO
#| message: false
#| warning: false

fly_into_sfo %>% 
  
  # sort 'name' of airline by the numbers it times to flew to SFO
  mutate(name = fct_reorder(name, count)) %>% 
  
  ggplot() +
  
  aes(x = count, 
      y = name) +
  
  # a simple bar/column plot
  geom_col() +
  
  # add labels, so each bar shows the % of total flights 
  geom_text(aes(label = percent),
             hjust = 1, 
             colour = "white", 
             size = 5)+
  
  # add labels to help our audience  
  labs(title="Which airline dominates the NYC to SFO route?", 
       subtitle = "as % of total flights in 2013",
       x= "Number of flights",
       y= NULL) +
  
  theme_minimal() + 
  
  # change the theme-- i just googled those , but you can use the ggThemeAssist add-in
  # https://cran.r-project.org/web/packages/ggThemeAssist/index.html
  
  theme(#
    # so title is left-aligned
    plot.title.position = "plot",
    
    # text in axes appears larger        
    axis.text = element_text(size=12),
    
    # title text is bigger
    plot.title = element_text(size=18)
      ) +

  # add one final layer of NULL, so if you comment out any lines
  # you never end up with a hanging `+` that awaits another ggplot layer
  NULL
 
 
```

## Problem 9: Let's take a look at cancellations of flights to SFO. We create a new dataframe `cancellations` as follows

```{r}

cancellations <- flights %>% 
  
  # just filter for destination == 'SFO'
  filter(dest == 'SFO') %>% 
  
  # a cancelled flight is one with no `dep_time` 
  filter(is.na(dep_time))

cancellations

```

I want you to think how we would organise our data manipulation to create the following plot. No need to write the code, just explain in words how you would go about it.

![](images/sfo-cancellations.png)

To create this plot we would first group the data by month and carrier (which we need to rename), and then filter to ensure that origin = EWR or JFK.

We then create a box plot using ggplot with month as the label variable, doing a facet_wrap by both carrier and origin to ensure that there is a new plot for each specific combination of those variables.

We need to add the appropriate title, and adjust the theme to how we want it.

## Problem 10: On your own -- Hollywood Age Gap

The website https://hollywoodagegap.com is a record of *THE AGE DIFFERENCE IN YEARS BETWEEN MOVIE LOVE INTERESTS*. This is an informational site showing the age gap between movie love interests and the data follows certain rules:

-   The two (or more) actors play actual love interests (not just friends, coworkers, or some other non-romantic type of relationship)
-   The youngest of the two actors is at least 17 years old
-   No animated characters

The age gaps dataset includes "gender" columns, which always contain the values "man" or "woman". These values appear to indicate how the characters in each film identify and some of these values do not match how the actor identifies. We apologize if any characters are misgendered in the data!

The following is a data dictionary of the variables used

| variable            | class     | description                                                                                             |
|:--------------------|:----------|:--------------------------------------------------------------------------------------------------------|
| movie_name          | character | Name of the film                                                                                        |
| release_year        | integer   | Release year                                                                                            |
| director            | character | Director of the film                                                                                    |
| age_difference      | integer   | Age difference between the characters in whole years                                                    |
| couple_number       | integer   | An identifier for the couple in case multiple couples are listed for this film                          |
| actor_1\_name       | character | The name of the older actor in this couple                                                              |
| actor_2\_name       | character | The name of the younger actor in this couple                                                            |
| character_1\_gender | character | The gender of the older character, as identified by the person who submitted the data for this couple   |
| character_2\_gender | character | The gender of the younger character, as identified by the person who submitted the data for this couple |
| actor_1\_birthdate  | date      | The birthdate of the older member of the couple                                                         |
| actor_2\_birthdate  | date      | The birthdate of the younger member of the couple                                                       |
| actor_1\_age        | integer   | The age of the older actor when the film was released                                                   |
| actor_2\_age        | integer   | The age of the younger actor when the film was released                                                 |

```{r}

age_gaps <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-02-14/age_gaps.csv')

age_gaps
#A: Examining the distribution of age_difference and finding the mean ('typical') age difference

plot(density(age_gaps$age_difference))
  #This density plot shows that the most common age gap is around 4 years

hist(age_gaps$age_difference)
  #This histogram shows that the vast majority of age gaps are between 0 and 20      years

boxplot(age_gaps$age_difference)
  #This boxplot shows that there are a number of outliers with very large age gaps   of more than 30 years
  
age_gaps %>% 
  summarize(
    typical_age_gap = mean(age_difference),
    maximum = max(age_difference),
    minimum = min(age_difference),
    median = median(age_difference),
    sd = sd(age_difference)
    ) %>% 
    mutate(
      across(where(is.numeric), ~ round(., 2))
      )
  #This table shows some summary statistics, including the 'typical'/mean age gap which is 10.42, the maximum age gap which is 52, and the minimum age gap which is 0


#B: The half plus 7 rule
half_plus_seven_rule <- age_gaps %>% 
  select(movie_name, actor_1_age, actor_2_age) %>% 
  #In order for the 'half plus 7' rule to apply, the 'actor_2_age' variable must be more than 'half plus 7' of the actor 1 age
  mutate(half_plus_seven = ((actor_1_age/2) + 7),
         test = actor_2_age - half_plus_seven
         #The 'test' is positive if the test is passed, and negative if not
         ) %>% 
  arrange(test) %>% 
  mutate(passed = case_when(
    test >= 0 ~ "Yes",
    TRUE ~ "No"
  )) %>% 
  #Using the mutate and case_when function I have created 2 outcomes, either 'yes' or 'no' to whether the test is passed
  group_by(passed) %>% 
  #Finally I count the number of times the test is either passed or not
  count(passed)


ggplot(data = half_plus_seven_rule, aes(x = passed, y = n)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "Passed?", y = "Count") +
  ggtitle("How many love interests passed the 'Half your age plus 7' rule?")
#I used ggplot to show the number of occasions in which the rule is passed or not




#C: Which movie has the greatest number of love interests?
number_of_love_interests <- age_gaps %>% 
  group_by(movie_name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  head(1)
  #To find which movie has the greatest number of love interests, I first grouped by movie name, then counted the number of times each movie appeared, then sorted by n, then took the film with the most appearances - which was (unsurprisingly), Love Actually with 7 love interests


#D: Which actor/actresses has the greatest number of love interests?

  #The challenge here is that some actors may appear as both actor_1 and actor_2 across different films, so we need to collate the data
pivot_longer(
  data = age_gaps, cols = c("actor_1_name", "actor_2_name"), names_to = "Actor", values_to = "Name") %>% 
  #I pivot longer to get all of the names of actors in one column, allowing me to find the most numerous names regardless of whether they originally appeared as 'Actor 1' or 'Actor 2'
  select(Name) %>%
  group_by(Name) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  head(5)
  
  #The 5 actors/actresses that appear the most can be seen in this table, all are male and the lowest number of appearances is 17



#E: Is the mean/median age difference staying constant over the years?
age_gaps_over_time <- age_gaps %>% 
  mutate(age_gap = actor_1_age - actor_2_age) %>% 
  select(age_gap, release_year) %>% 
  #cor() %>%  
  GGally::ggpairs()
  #This correlation test shows that there is a negative correlation between age gap and release year, suggesting that the general age gap in films has come down over time

age_gaps_over_time_mean <- age_gaps %>% 
  mutate(age_gap = actor_1_age - actor_2_age) %>% 
  select(age_gap, release_year) %>%
  group_by(release_year) %>% 
  arrange(release_year) %>% 
  summarize(mean_age_gap = mean(age_gap), 
            median_age_gap = median(age_gap)) %>% 
  cor()

#This correlation table shows that there is a negative correlation between release year and both mean age gap (-0.486) and median age gap (-0.484)
  


#F: How often does Hollywood depict same gender love interests?
same_gender_love_interests <- age_gaps %>% 
  filter(character_1_gender == character_2_gender) %>% 
  count()
  #I found the number of times that a film has depicted a same gender couple (where character 1 gender = character 2 gender)

total_love_interests <- age_gaps %>% 
  count()
  #I found the total number of love interests 

proportion_of_same_gender_love_interests <- (same_gender_love_interests$n/total_love_interests$n)
  #I calculate the proportion of love interests that are same gender

proportion_of_same_gender_love_interests

#We can see that only 1.99% of love interests depicted by Hollywood show same gender couples
```

How would you explore this data set? Here are some ideas of tables/ graphs to help you with your analysis

-   How is `age_difference` distributed? What's the 'typical' `age_difference` in movies?

-   The `half plus seven\` rule. Large age disparities in relationships carry certain stigmas. One popular rule of thumb is the [half-your-age-plus-seven](https://en.wikipedia.org/wiki/Age_disparity_in_sexual_relationships#The_.22half-your-age-plus-seven.22_rule) rule. This rule states you should never date anyone under half your age plus seven, establishing a minimum boundary on whom one can date. In order for a dating relationship to be acceptable under this rule, your partner's age must be:

$$\frac{\text{Your age}}{2} + 7 < \text{Partner Age} < (\text{Your age} - 7) * 2$$ How frequently does this rule apply in this dataset?

-   Which movie has the greatest number of love interests?
-   Which actors/ actresses have the greatest number of love interests in this dataset?
-   Is the mean/median age difference staying constant over the years (1935 - 2022)?
-   How frequently does Hollywood depict same-gender love interests?

# Deliverables

There is a lot of explanatory text, comments, etc. You do not need these, so delete them and produce a stand-alone document that you could share with someone. Render the edited and completed Quarto Markdown (qmd) file as a Word document (use the "Render" button at the top of the script editor window) and upload it to Canvas. You must be commiting and pushing tour changes to your own Github repo as you go along.

# Details

-   Who did you collaborate with: TYPE NAMES HERE
-   Approximately how much time did you spend on this problem set: ANSWER HERE
-   What, if anything, gave you the most trouble: ANSWER HERE

**Please seek out help when you need it,** and remember the [15-minute rule](https://mam2022.netlify.app/syllabus/#the-15-minute-rule){target="_blank"}. You know enough R (and have enough examples of code from class and your readings) to be able to do this. If you get stuck, ask for help from others, post a question on Slack-- and remember that I am here to help too!

> As a true test to yourself, do you understand the code you submitted and are you able to explain it to someone else?

# Rubric

13/13: Problem set is 100% completed. Every question was attempted and answered, and most answers are correct. Code is well-documented (both self-documented and with additional comments as necessary). Used tidyverse, instead of base R. Graphs and tables are properly labelled. Analysis is clear and easy to follow, either because graphs are labeled clearly or you've written additional text to describe how you interpret the output. Multiple Github commits. Work is exceptional. I will not assign these often.

8/13: Problem set is 60--80% complete and most answers are correct. This is the expected level of performance. Solid effort. Hits all the elements. No clear mistakes. Easy to follow (both the code and the output). A few Github commits.

5/13: Problem set is less than 60% complete and/or most answers are incorrect. This indicates that you need to improve next time. I will hopefully not assign these often. Displays minimal effort. Doesn't complete all components. Code is poorly written and not documented. Uses the same type of plot for each graph, or doesn't use plots appropriate for the variables being analyzed. No Github commits.
